{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoA Prediction: Data Exploration and Processing\n",
    "\n",
    "This notebook demonstrates the data collection and processing pipeline for the MoA prediction framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from moa.utils.config import Config\n",
    "from moa.data.collectors import DataCollectorFactory\n",
    "from moa.data.processors import DataProcessor\n",
    "from moa.data.validators import DataValidator\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Summary:\n",
      "Prediction type: multi_label\n",
      "Enabled modalities: {'chemistry': True, 'perturbation': True, 'targets': True, 'pathways': True, 'structures': False}\n",
      "ChEMBL version: None\n",
      "Data benchmarks: ['chembl', 'drugbank', 'lincs_l1000']\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config = Config('../configs/config.yaml')\n",
    "\n",
    "# Display key configuration settings\n",
    "print(\"Configuration Summary:\")\n",
    "print(f\"Prediction type: {config.get('scope.prediction_type')}\")\n",
    "print(f\"Enabled modalities: {config.get('scope.modalities')}\")\n",
    "print(f\"ChEMBL version: {config.get('chembl.version')}\")\n",
    "print(f\"Data benchmarks: {config.get('data.benchmarks')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection Demo\n",
    "\n",
    "**Note**: This is a demonstration. In practice, you would run the data collection scripts to download full datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset:\n",
      "  molecule_chembl_id                                canonical_smiles  \\\n",
      "0            CHEMBL1                                             CCO   \n",
      "1            CHEMBL2                        CC(=O)OC1=CC=CC=C1C(=O)O   \n",
      "2            CHEMBL3                    CN1C=NC2=C1C(=O)N(C(=O)N2C)C   \n",
      "3            CHEMBL4                   CC(C)CC1=CC=C(C=C1)C(C)C(=O)O   \n",
      "4            CHEMBL5  CN(C)CCOC1=CC=C(C=C1)C(C2=CC=CC=C2)C3=CC=CC=C3   \n",
      "\n",
      "                mechanism_of_action target_chembl_id  \n",
      "0                    CNS depressant          CHEMBL1  \n",
      "1          Cyclooxygenase inhibitor        CHEMBL230  \n",
      "2     Adenosine receptor antagonist       CHEMBL1824  \n",
      "3          Cyclooxygenase inhibitor        CHEMBL230  \n",
      "4  Histamine H1 receptor antagonist        CHEMBL231  \n"
     ]
    }
   ],
   "source": [
    "# Create a small sample dataset for demonstration\n",
    "sample_data = {\n",
    "    'molecule_chembl_id': ['CHEMBL1', 'CHEMBL2', 'CHEMBL3', 'CHEMBL4', 'CHEMBL5'],\n",
    "    'canonical_smiles': [\n",
    "        'CCO',  # Ethanol\n",
    "        'CC(=O)OC1=CC=CC=C1C(=O)O',  # Aspirin\n",
    "        'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',  # Caffeine\n",
    "        'CC(C)CC1=CC=C(C=C1)C(C)C(=O)O',  # Ibuprofen\n",
    "        'CN(C)CCOC1=CC=C(C=C1)C(C2=CC=CC=C2)C3=CC=CC=C3'  # Diphenhydramine\n",
    "    ],\n",
    "    'mechanism_of_action': [\n",
    "        'CNS depressant',\n",
    "        'Cyclooxygenase inhibitor',\n",
    "        'Adenosine receptor antagonist',\n",
    "        'Cyclooxygenase inhibitor',\n",
    "        'Histamine H1 receptor antagonist'\n",
    "    ],\n",
    "    'target_chembl_id': ['CHEMBL1', 'CHEMBL230', 'CHEMBL1824', 'CHEMBL230', 'CHEMBL231']\n",
    "}\n",
    "\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "print(\"Sample dataset:\")\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SMILES...\n",
      "Processed 0 compounds\n",
      "Empty DataFrame\n",
      "Columns: [canonical_smiles, standardized_smiles]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Initialize data processor\n",
    "processor = DataProcessor(config)\n",
    "\n",
    "# Process SMILES\n",
    "print(\"Processing SMILES...\")\n",
    "processed_df = processor.smiles_processor.process_smiles_column(sample_df)\n",
    "print(f\"Processed {len(processed_df)} compounds\")\n",
    "print(processed_df[['canonical_smiles', 'standardized_smiles']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MoA labels...\n",
      "Created 3 label columns:\n",
      "['moa_cleaned', 'moa_list', 'moa_classes']\n",
      "\n",
      "Label matrix:\n",
      "Empty DataFrame\n",
      "Columns: [moa_cleaned, moa_list, moa_classes]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Process labels\n",
    "print(\"Processing MoA labels...\")\n",
    "processed_df = processor.label_processor.process_moa_labels(processed_df)\n",
    "\n",
    "# Show label columns\n",
    "label_cols = [col for col in processed_df.columns if col.startswith('moa_')]\n",
    "print(f\"Created {len(label_cols)} label columns:\")\n",
    "print(label_cols[:10])  # Show first 10\n",
    "\n",
    "if len(label_cols) > 0:\n",
    "    print(\"\\nLabel matrix:\")\n",
    "    print(processed_df[label_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running validation checks...\n",
      "\n",
      "SMILES validation:\n",
      "  ✓ smiles_column_exists\n",
      "  ✓ no_missing_smiles\n",
      "  ✓ all_smiles_valid\n",
      "  ✓ no_duplicate_smiles\n",
      "\n",
      "Label validation:\n",
      "  ✓ label_columns_exist\n",
      "  ✓ no_missing_labels\n",
      "  ✗ sufficient_samples_per_label\n",
      "  ✓ no_empty_labels\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheck\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Dataset size validation\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m size_results \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mvalidate_dataset_size(processed_df)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDataset size validation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m check, passed \u001b[38;5;129;01min\u001b[39;00m size_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/jaijaish98/Projects/Moa/Moa/notebooks/../moa/data/validators.py:116\u001b[0m, in \u001b[0;36mDataValidator.validate_dataset_size\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    113\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    115\u001b[0m min_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation.min_dataset_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msufficient_dataset_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_samples\n\u001b[1;32m    118\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset size validation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples (min: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Initialize validator\n",
    "validator = DataValidator(config)\n",
    "\n",
    "# Run validation checks\n",
    "print(\"Running validation checks...\")\n",
    "\n",
    "# SMILES validation\n",
    "smiles_results = validator.validate_smiles(processed_df)\n",
    "print(\"\\nSMILES validation:\")\n",
    "for check, passed in smiles_results.items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"  {status} {check}\")\n",
    "\n",
    "# Label validation\n",
    "label_results = validator.validate_labels(processed_df)\n",
    "print(\"\\nLabel validation:\")\n",
    "for check, passed in label_results.items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"  {status} {check}\")\n",
    "\n",
    "# Dataset size validation\n",
    "size_results = validator.validate_dataset_size(processed_df)\n",
    "print(\"\\nDataset size validation:\")\n",
    "for check, passed in size_results.items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"  {status} {check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      4\u001b[0m moa_counts \u001b[38;5;241m=\u001b[39m processed_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmoa_cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m----> 5\u001b[0m moa_counts\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of Mechanisms of Action\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMechanism of Action\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/plotting/_core.py:1030\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             label_name \u001b[38;5;241m=\u001b[39m label_kw \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   1028\u001b[0m             data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m label_name\n\u001b[0;32m-> 1030\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_backend\u001b[38;5;241m.\u001b[39mplot(data, kind\u001b[38;5;241m=\u001b[39mkind, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/plotting/_matplotlib/__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_ax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax)\n\u001b[1;32m     70\u001b[0m plot_obj \u001b[38;5;241m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 71\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mgenerate()\n\u001b[1;32m     72\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_obj\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/plotting/_matplotlib/core.py:508\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_plot_logic_common(ax)\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_plot_logic(ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/plotting/_matplotlib/core.py:1972\u001b[0m, in \u001b[0;36mBarPlot._post_plot_logic\u001b[0;34m(self, ax, data)\u001b[0m\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1970\u001b[0m     str_index \u001b[38;5;241m=\u001b[39m [pprint_thing(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[0;32m-> 1972\u001b[0m s_edge \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39max_pos[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.25\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlim_offset\n\u001b[1;32m   1973\u001b[0m e_edge \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39max_pos[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.25\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbar_width \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlim_offset\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decorate_ticks(ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index_name(), str_index, s_edge, e_edge)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Visualize MoA distribution\n",
    "if 'moa_cleaned' in processed_df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    moa_counts = processed_df['moa_cleaned'].value_counts()\n",
    "    moa_counts.plot(kind='bar')\n",
    "    plt.title('Distribution of Mechanisms of Action')\n",
    "    plt.xlabel('Mechanism of Action')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Molecular weight distribution (if RDKit is available)\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import Descriptors\n",
    "    \n",
    "    def get_mol_weight(smiles):\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            return Descriptors.MolWt(mol) if mol else None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    processed_df['mol_weight'] = processed_df['standardized_smiles'].apply(get_mol_weight)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    processed_df['mol_weight'].dropna().hist(bins=20, alpha=0.7)\n",
    "    plt.title('Distribution of Molecular Weights')\n",
    "    plt.xlabel('Molecular Weight (Da)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"RDKit not available for molecular property calculations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "This notebook demonstrated the basic data processing pipeline. Next steps include:\n",
    "\n",
    "1. **Full Data Collection**: Run the data collection scripts to download complete datasets from ChEMBL, LINCS, and other sources\n",
    "2. **Feature Engineering**: Implement chemical graph features, mechanism tokens, and perturbational biology features\n",
    "3. **Model Development**: Build the multi-modal architecture with hypergraph fusion\n",
    "4. **Training Pipeline**: Implement the training loop with multiple objectives\n",
    "5. **Evaluation**: Comprehensive evaluation on multiple splits and metrics\n",
    "\n",
    "### Commands to run full pipeline:\n",
    "\n",
    "```bash\n",
    "# Download data\n",
    "python scripts/download_data.py --sources chembl reactome\n",
    "\n",
    "# Process data\n",
    "python scripts/process_data.py --create-splits --validate\n",
    "\n",
    "# Or use the CLI\n",
    "moa-data collect --source chembl\n",
    "moa-data process --create-splits\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
