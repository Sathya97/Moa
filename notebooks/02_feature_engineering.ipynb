{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoA Prediction: Novel Feature Engineering\n",
    "\n",
    "This notebook demonstrates the novel feature engineering approaches implemented in Phase 2:\n",
    "\n",
    "1. **Chemical Graph Features** with counterfactual substructure analysis\n",
    "2. **Mechanism Tokens (MechTokens)** - ontology-aware embeddings\n",
    "3. **Perturbational Biology Features** from LINCS L1000\n",
    "4. **Protein Pocket Features** (optional)\n",
    "\n",
    "These features represent the key innovations that differentiate our approach from existing MoA prediction methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "\n",
    "from moa.utils.config import Config\n",
    "from moa.features.chemical import ChemicalFeatureExtractor\n",
    "from moa.features.mechanism_tokens import MechTokenFeatureExtractor\n",
    "from moa.features.perturbational import PerturbationalFeatureExtractor\n",
    "from moa.features.feature_extractor import MultiModalFeatureExtractor\n",
    "from moa.data.processors import DataProcessor\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = Config('../configs/config.yaml')\n",
    "\n",
    "# Enable all modalities for demonstration\n",
    "config.set(\"scope.modalities.chemistry\", True)\n",
    "config.set(\"scope.modalities.targets\", True)\n",
    "config.set(\"scope.modalities.pathways\", True)\n",
    "config.set(\"scope.modalities.perturbation\", True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"Enabled modalities: {config.get('scope.modalities')}\")\n",
    "print(f\"Counterfactual analysis: {config.get('features.chemistry.substructure_analysis.enable_counterfactual')}\")\n",
    "print(f\"MechToken embedding dim: {config.get('features.mechanism_tokens.embedding_dim')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset with diverse MoAs\n",
    "sample_data = pd.DataFrame({\n",
    "    'molecule_chembl_id': [\n",
    "        'CHEMBL25', 'CHEMBL521', 'CHEMBL113', 'CHEMBL1200766', 'CHEMBL154',\n",
    "        'CHEMBL6', 'CHEMBL1201585', 'CHEMBL744', 'CHEMBL1200960', 'CHEMBL1201'\n",
    "    ],\n",
    "    'canonical_smiles': [\n",
    "        'CCO',  # Ethanol\n",
    "        'CC(=O)OC1=CC=CC=C1C(=O)O',  # Aspirin\n",
    "        'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',  # Caffeine\n",
    "        'CC(C)CC1=CC=C(C=C1)C(C)C(=O)O',  # Ibuprofen\n",
    "        'CN(C)CCOC1=CC=C(C=C1)C(C2=CC=CC=C2)C3=CC=CC=C3',  # Diphenhydramine\n",
    "        'CC(C)(C)NCC(C1=CC(=C(C=C1)O)CO)O',  # Salbutamol\n",
    "        'CN1CCN(CC1)C2=C(C=C3C(=C2)N=CN=C3NC4=CC=C(C=C4)OC)F',  # Gefitinib\n",
    "        'CC1=C(C=C(C=C1)C(=O)C2=CC=CC=C2)C',  # Tolmetin\n",
    "        'COC1=CC=C(C=C1)C2=CC(=NN2C3=CC=C(C=C3)S(=O)(=O)N)C(F)(F)F',  # Celecoxib\n",
    "        'CN(C)CCCN1C2=CC=CC=C2SC3=C1C=C(C=C3)Cl'  # Chlorpromazine\n",
    "    ],\n",
    "    'mechanism_of_action': [\n",
    "        'CNS depressant',\n",
    "        'Cyclooxygenase inhibitor',\n",
    "        'Adenosine receptor antagonist',\n",
    "        'Cyclooxygenase inhibitor',\n",
    "        'Histamine H1 receptor antagonist',\n",
    "        'Beta-2 adrenergic receptor agonist',\n",
    "        'EGFR tyrosine kinase inhibitor',\n",
    "        'Cyclooxygenase inhibitor',\n",
    "        'Cyclooxygenase-2 inhibitor',\n",
    "        'Dopamine receptor antagonist'\n",
    "    ],\n",
    "    'target_chembl_id': [\n",
    "        'CHEMBL1', 'CHEMBL230', 'CHEMBL1824', 'CHEMBL230', 'CHEMBL231',\n",
    "        'CHEMBL210', 'CHEMBL203', 'CHEMBL230', 'CHEMBL230', 'CHEMBL217'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(f\"Created dataset with {len(sample_data)} compounds\")\n",
    "print(\"\\nMoA distribution:\")\n",
    "print(sample_data['mechanism_of_action'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chemical Graph Features with Counterfactual Analysis\n",
    "\n",
    "Our novel approach identifies causal molecular substructures by analyzing how their removal affects MoA prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data for feature extraction\n",
    "processor = DataProcessor(config)\n",
    "processed_data = processor.smiles_processor.process_smiles_column(sample_data)\n",
    "processed_data = processor.label_processor.process_moa_labels(processed_data)\n",
    "\n",
    "print(f\"Processed {len(processed_data)} compounds\")\n",
    "print(f\"Created {len([c for c in processed_data.columns if c.startswith('moa_')])} MoA labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract chemical features with counterfactual analysis\n",
    "chemical_extractor = ChemicalFeatureExtractor(config)\n",
    "\n",
    "smiles_list = processed_data['standardized_smiles'].tolist()\n",
    "\n",
    "# Create binary label matrix for counterfactual analysis\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(processed_data['moa_list'])\n",
    "moa_names = list(mlb.classes_)\n",
    "\n",
    "print(f\"Extracting chemical features for {len(smiles_list)} compounds...\")\n",
    "chemical_features = chemical_extractor.extract_features(smiles_list, labels, moa_names)\n",
    "\n",
    "print(\"\\nChemical features extracted:\")\n",
    "for key, value in chemical_features.items():\n",
    "    if isinstance(value, list):\n",
    "        print(f\"  {key}: {len(value)} items\")\n",
    "    elif isinstance(value, dict):\n",
    "        print(f\"  {key}: {len(value)} entries\")\n",
    "    else:\n",
    "        print(f\"  {key}: {type(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize molecular graphs\n",
    "molecular_graphs = chemical_features['molecular_graphs']\n",
    "valid_graphs = [g for g in molecular_graphs if g is not None]\n",
    "\n",
    "print(f\"Generated {len(valid_graphs)} valid molecular graphs\")\n",
    "\n",
    "if valid_graphs:\n",
    "    # Show graph statistics\n",
    "    node_counts = [g.x.shape[0] for g in valid_graphs]\n",
    "    edge_counts = [g.edge_index.shape[1] for g in valid_graphs]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.hist(node_counts, bins=10, alpha=0.7)\n",
    "    ax1.set_xlabel('Number of Nodes')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title('Distribution of Graph Sizes (Nodes)')\n",
    "    \n",
    "    ax2.hist(edge_counts, bins=10, alpha=0.7)\n",
    "    ax2.set_xlabel('Number of Edges')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title('Distribution of Graph Sizes (Edges)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average nodes per graph: {np.mean(node_counts):.1f}\")\n",
    "    print(f\"Average edges per graph: {np.mean(edge_counts):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze counterfactual substructure scores\n",
    "if 'counterfactual_scores' in chemical_features:\n",
    "    cf_scores = chemical_features['counterfactual_scores']\n",
    "    causal_fragments = chemical_features['causal_fragments']\n",
    "    \n",
    "    print(f\"Counterfactual analysis completed for {len(cf_scores)} MoAs\")\n",
    "    \n",
    "    # Show top causal fragments for each MoA\n",
    "    for moa, fragments in list(causal_fragments.items())[:3]:\n",
    "        print(f\"\\nTop causal fragments for '{moa}':\")\n",
    "        for i, (fragment, score) in enumerate(fragments[:5]):\n",
    "            print(f\"  {i+1}. {fragment}: {score:.4f}\")\n",
    "    \n",
    "    # Visualize fragment importance distribution\n",
    "    all_scores = []\n",
    "    for moa_scores in cf_scores.values():\n",
    "        all_scores.extend(moa_scores.values())\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(all_scores, bins=30, alpha=0.7)\n",
    "    plt.xlabel('Counterfactual Importance Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Fragment Importance Scores')\n",
    "    plt.axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Neutral')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nFragment importance statistics:\")\n",
    "    print(f\"  Mean: {np.mean(all_scores):.4f}\")\n",
    "    print(f\"  Std: {np.std(all_scores):.4f}\")\n",
    "    print(f\"  Positive scores (causal): {sum(1 for s in all_scores if s > 0)} / {len(all_scores)}\")\n",
    "else:\n",
    "    print(\"Counterfactual analysis not performed (requires labels)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mechanism Tokens (MechTokens)\n",
    "\n",
    "Novel ontology-aware embeddings that encode drug-target-pathway-MoA relationships using graph neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data sources for mechanism tokens\n",
    "data_sources = {\n",
    "    'mechanisms': pd.DataFrame({\n",
    "        'molecule_chembl_id': processed_data['molecule_chembl_id'].tolist(),\n",
    "        'target_chembl_id': processed_data['target_chembl_id'].tolist(),\n",
    "        'mechanism_of_action': processed_data['mechanism_of_action'].tolist()\n",
    "    }),\n",
    "    'targets': pd.DataFrame({\n",
    "        'target_chembl_id': ['CHEMBL1', 'CHEMBL230', 'CHEMBL1824', 'CHEMBL210', 'CHEMBL203', 'CHEMBL231', 'CHEMBL217'],\n",
    "        'pref_name': ['Alcohol dehydrogenase', 'Cyclooxygenase-1', 'Adenosine A2a receptor', \n",
    "                     'Beta-2 adrenergic receptor', 'EGFR', 'Histamine H1 receptor', 'Dopamine D2 receptor'],\n",
    "        'target_type': ['PROTEIN'] * 7\n",
    "    }),\n",
    "    'pathways': pd.DataFrame({\n",
    "        'stId': ['R-HSA-1234', 'R-HSA-5678', 'R-HSA-9012'],\n",
    "        'displayName': ['Alcohol metabolism', 'Arachidonic acid metabolism', 'Adenosine signaling']\n",
    "    }),\n",
    "    'protein_pathways': pd.DataFrame({\n",
    "        'uniprot_id': ['P00325', 'P23219', 'P29274'],\n",
    "        'pathway_id': ['R-HSA-1234', 'R-HSA-5678', 'R-HSA-9012']\n",
    "    })\n",
    "}\n",
    "\n",
    "print(\"Created sample data sources for mechanism tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mechanism tokens\n",
    "mechtoken_extractor = MechTokenFeatureExtractor(config)\n",
    "\n",
    "print(\"Building mechanism tokens...\")\n",
    "mechtoken_extractor.build_mechanism_tokens(data_sources)\n",
    "\n",
    "# Analyze the ontology graph\n",
    "ontology_graph = mechtoken_extractor.ontology_graph\n",
    "print(f\"\\nOntology graph statistics:\")\n",
    "print(f\"  Nodes: {ontology_graph.number_of_nodes()}\")\n",
    "print(f\"  Edges: {ontology_graph.number_of_edges()}\")\n",
    "\n",
    "# Analyze node types\n",
    "node_types = mechtoken_extractor.ontology_builder.node_types\n",
    "type_counts = {}\n",
    "for node_type in node_types.values():\n",
    "    type_counts[node_type] = type_counts.get(node_type, 0) + 1\n",
    "\n",
    "print(f\"\\nNode type distribution:\")\n",
    "for node_type, count in type_counts.items():\n",
    "    print(f\"  {node_type}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the ontology graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a simplified view of the graph\n",
    "pos = nx.spring_layout(ontology_graph, k=2, iterations=50)\n",
    "\n",
    "# Color nodes by type\n",
    "node_colors = []\n",
    "color_map = {'drug': 'lightblue', 'target': 'lightgreen', 'pathway': 'orange', 'moa': 'pink'}\n",
    "\n",
    "for node in ontology_graph.nodes():\n",
    "    node_type = node_types.get(node, 'unknown')\n",
    "    node_colors.append(color_map.get(node_type, 'gray'))\n",
    "\n",
    "nx.draw(ontology_graph, pos, \n",
    "        node_color=node_colors, \n",
    "        node_size=300, \n",
    "        with_labels=False, \n",
    "        edge_color='gray', \n",
    "        alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=color, markersize=10, label=node_type.title())\n",
    "                  for node_type, color in color_map.items()]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.title('Biological Ontology Graph\\n(Drug-Target-Pathway-MoA Relationships)')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract compound-specific mechanism tokens\n",
    "compound_ids = processed_data['molecule_chembl_id'].tolist()\n",
    "compound_tokens = mechtoken_extractor.extract_compound_tokens(compound_ids)\n",
    "\n",
    "print(f\"Extracted mechanism tokens for {len(compound_tokens)} compounds\")\n",
    "\n",
    "if compound_tokens:\n",
    "    token_dims = [token.shape[0] for token in compound_tokens.values()]\n",
    "    print(f\"Token dimension: {token_dims[0]}\")\n",
    "    \n",
    "    # Visualize token similarity\n",
    "    token_matrix = np.array(list(compound_tokens.values()))\n",
    "    \n",
    "    # Compute pairwise cosine similarity\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similarity_matrix = cosine_similarity(token_matrix)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(similarity_matrix, \n",
    "                xticklabels=[f\"C{i+1}\" for i in range(len(compound_ids))],\n",
    "                yticklabels=[f\"C{i+1}\" for i in range(len(compound_ids))],\n",
    "                annot=True, fmt='.2f', cmap='viridis')\n",
    "    plt.title('Compound Mechanism Token Similarity Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nToken similarity statistics:\")\n",
    "    # Exclude diagonal (self-similarity)\n",
    "    off_diagonal = similarity_matrix[np.triu_indices_from(similarity_matrix, k=1)]\n",
    "    print(f\"  Mean similarity: {np.mean(off_diagonal):.3f}\")\n",
    "    print(f\"  Std similarity: {np.std(off_diagonal):.3f}\")\n",
    "    print(f\"  Min similarity: {np.min(off_diagonal):.3f}\")\n",
    "    print(f\"  Max similarity: {np.max(off_diagonal):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perturbational Biology Features\n",
    "\n",
    "Gene expression signatures from LINCS L1000 mapped to pathway activity scores using GSVA/ssGSEA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample LINCS signatures\n",
    "lincs_signatures = pd.DataFrame({\n",
    "    'sig_id': [f'SIG_{i:04d}' for i in range(30)],\n",
    "    'pert_iname': ['compound_25', 'compound_521', 'compound_113'] * 10,\n",
    "    'cell_id': ['MCF7', 'PC3', 'A549'] * 10,\n",
    "    'pert_time': ['24h'] * 30,\n",
    "    'pert_dose': ['10 µM'] * 30\n",
    "})\n",
    "\n",
    "data_sources['lincs_signatures'] = lincs_signatures\n",
    "\n",
    "print(f\"Created sample LINCS signatures: {len(lincs_signatures)} signatures\")\n",
    "print(f\"Unique compounds: {lincs_signatures['pert_iname'].nunique()}\")\n",
    "print(f\"Cell lines: {lincs_signatures['cell_id'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract perturbational features\n",
    "perturbational_extractor = PerturbationalFeatureExtractor(config)\n",
    "\n",
    "compound_names = ['compound_25', 'compound_521', 'compound_113']\n",
    "\n",
    "print(\"Extracting perturbational features...\")\n",
    "perturbational_features = perturbational_extractor.extract_perturbational_features(\n",
    "    lincs_signatures, compound_names\n",
    ")\n",
    "\n",
    "print(\"\\nPerturbational features extracted:\")\n",
    "for key, value in perturbational_features.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  {key}: {len(value)} compounds\")\n",
    "        if value:\n",
    "            sample_value = list(value.values())[0]\n",
    "            if isinstance(sample_value, np.ndarray):\n",
    "                print(f\"    Dimension: {sample_value.shape}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  {key}: {len(value)} items\")\n",
    "    else:\n",
    "        print(f\"  {key}: {type(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize meta-signatures\n",
    "if 'meta_signatures' in perturbational_features:\n",
    "    meta_signatures = perturbational_features['meta_signatures']\n",
    "    gene_names = perturbational_features.get('gene_names', [])\n",
    "    \n",
    "    # Create signature matrix\n",
    "    signature_matrix = np.array([meta_signatures[compound] for compound in compound_names])\n",
    "    \n",
    "    print(f\"Meta-signature matrix shape: {signature_matrix.shape}\")\n",
    "    \n",
    "    # Visualize signature heatmap (first 50 genes)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(signature_matrix[:, :50], \n",
    "                xticklabels=[f\"G{i+1}\" for i in range(50)],\n",
    "                yticklabels=compound_names,\n",
    "                cmap='RdBu_r', center=0)\n",
    "    plt.title('Gene Expression Meta-Signatures (First 50 Genes)')\n",
    "    plt.xlabel('Genes')\n",
    "    plt.ylabel('Compounds')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show signature statistics\n",
    "    print(f\"\\nSignature statistics:\")\n",
    "    print(f\"  Mean expression: {np.mean(signature_matrix):.3f}\")\n",
    "    print(f\"  Std expression: {np.std(signature_matrix):.3f}\")\n",
    "    print(f\"  Min expression: {np.min(signature_matrix):.3f}\")\n",
    "    print(f\"  Max expression: {np.max(signature_matrix):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pathway activity scores\n",
    "if 'pathway_scores' in perturbational_features:\n",
    "    pathway_scores = perturbational_features['pathway_scores']\n",
    "    pathway_names = perturbational_features.get('pathway_names', [])\n",
    "    \n",
    "    # Create pathway score matrix\n",
    "    pathway_matrix = np.array([pathway_scores[compound] for compound in compound_names])\n",
    "    \n",
    "    print(f\"Pathway score matrix shape: {pathway_matrix.shape}\")\n",
    "    \n",
    "    # Visualize pathway scores\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(pathway_matrix, \n",
    "                xticklabels=[f\"P{i+1}\" for i in range(len(pathway_names))],\n",
    "                yticklabels=compound_names,\n",
    "                cmap='RdBu_r', center=0)\n",
    "    plt.title('Pathway Activity Scores')\n",
    "    plt.xlabel('Pathways')\n",
    "    plt.ylabel('Compounds')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show top activated/suppressed pathways for each compound\n",
    "    for i, compound in enumerate(compound_names):\n",
    "        scores = pathway_matrix[i]\n",
    "        top_activated = np.argsort(scores)[-3:][::-1]\n",
    "        top_suppressed = np.argsort(scores)[:3]\n",
    "        \n",
    "        print(f\"\\n{compound}:\")\n",
    "        print(f\"  Top activated pathways: {[f'P{j+1}' for j in top_activated]}\")\n",
    "        print(f\"  Top suppressed pathways: {[f'P{j+1}' for j in top_suppressed]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Modal Feature Integration\n",
    "\n",
    "Demonstration of the complete multi-modal feature extraction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all features using the unified interface\n",
    "multimodal_extractor = MultiModalFeatureExtractor(config)\n",
    "\n",
    "print(\"Extracting all multi-modal features...\")\n",
    "all_features = multimodal_extractor.extract_all_features(processed_data, data_sources)\n",
    "\n",
    "print(\"\\nMulti-modal feature extraction completed!\")\n",
    "print(f\"Extracted features from {len(all_features)} modalities:\")\n",
    "\n",
    "for modality, features in all_features.items():\n",
    "    print(f\"\\n{modality.upper()}:\")\n",
    "    for feature_type, feature_data in features.items():\n",
    "        if isinstance(feature_data, dict):\n",
    "            print(f\"  {feature_type}: {len(feature_data)} items\")\n",
    "        elif isinstance(feature_data, list):\n",
    "            print(f\"  {feature_type}: {len(feature_data)} items\")\n",
    "        else:\n",
    "            print(f\"  {feature_type}: {type(feature_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature dimensionality summary\n",
    "print(\"Feature Dimensionality Summary:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "total_features = 0\n",
    "\n",
    "for modality, features in all_features.items():\n",
    "    modality_features = 0\n",
    "    \n",
    "    if modality == \"chemistry\":\n",
    "        if \"molecular_descriptors\" in features:\n",
    "            desc_example = features[\"molecular_descriptors\"][0]\n",
    "            desc_count = sum(1 if not isinstance(v, np.ndarray) else len(v) for v in desc_example.values())\n",
    "            modality_features += desc_count\n",
    "            print(f\"  Chemical descriptors: ~{desc_count}\")\n",
    "    \n",
    "    elif modality == \"mechanism_tokens\":\n",
    "        if \"compound_tokens\" in features:\n",
    "            tokens = features[\"compound_tokens\"]\n",
    "            if tokens:\n",
    "                token_dim = list(tokens.values())[0].shape[0]\n",
    "                modality_features += token_dim\n",
    "                print(f\"  Mechanism tokens: {token_dim}\")\n",
    "    \n",
    "    elif modality == \"perturbation\":\n",
    "        if \"meta_signatures\" in features:\n",
    "            meta_sigs = features[\"meta_signatures\"]\n",
    "            if meta_sigs:\n",
    "                sig_dim = list(meta_sigs.values())[0].shape[0]\n",
    "                modality_features += sig_dim\n",
    "                print(f\"  Gene signatures: {sig_dim}\")\n",
    "        \n",
    "        if \"pathway_scores\" in features:\n",
    "            pathway_scores = features[\"pathway_scores\"]\n",
    "            if pathway_scores:\n",
    "                pathway_dim = list(pathway_scores.values())[0].shape[0]\n",
    "                modality_features += pathway_dim\n",
    "                print(f\"  Pathway scores: {pathway_dim}\")\n",
    "    \n",
    "    total_features += modality_features\n",
    "    print(f\"  {modality.title()} total: {modality_features}\")\n",
    "\n",
    "print(f\"\\nTotal feature dimensions: ~{total_features}\")\n",
    "print(\"\\nNote: This excludes graph features which have variable dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Next Steps\n",
    "\n",
    "### Novel Features Implemented:\n",
    "\n",
    "1. **Chemical Graph Features with Counterfactual Analysis**\n",
    "   - Molecular graphs with rich node/edge features\n",
    "   - Counterfactual substructure importance scoring\n",
    "   - Causal fragment identification for MoA prediction\n",
    "\n",
    "2. **Mechanism Tokens (MechTokens)**\n",
    "   - Ontology-aware embeddings of drug-target-pathway-MoA relationships\n",
    "   - Node2vec embeddings with hierarchical encoding\n",
    "   - Compound-specific token aggregation\n",
    "\n",
    "3. **Perturbational Biology Features**\n",
    "   - LINCS L1000 gene expression meta-signatures\n",
    "   - Pathway activity scores using GSVA/ssGSEA\n",
    "   - Multi-cell line aggregation\n",
    "\n",
    "4. **Protein Pocket Features (Optional)**\n",
    "   - 3D binding site encoding using PointNet/3D CNN\n",
    "   - AlphaFold structure integration\n",
    "   - Druggability scoring\n",
    "\n",
    "### Key Innovations:\n",
    "\n",
    "- **Counterfactual Analysis**: First application to molecular substructure analysis for MoA prediction\n",
    "- **MechTokens**: Novel ontology-aware embeddings that capture biological relationships\n",
    "- **Multi-modal Integration**: Unified framework for combining diverse biological data types\n",
    "- **Hierarchical Encoding**: Captures different levels of biological organization\n",
    "\n",
    "### Next Steps (Phase 3):\n",
    "\n",
    "1. **Model Architecture Development**\n",
    "   - Graph Transformer for chemical features\n",
    "   - Pathway Transformer for biological features\n",
    "   - Hypergraph fusion layer for multi-modal integration\n",
    "\n",
    "2. **Training Pipeline**\n",
    "   - Multi-objective loss functions\n",
    "   - Curriculum learning\n",
    "   - Modality dropout for robustness\n",
    "\n",
    "The feature engineering foundation is now complete and ready for model development!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
